#!/usr/bin/env python3
"""
Comprehensive QA Validation - Matrix Restoration
End-to-end validation of the restored matrix functionality
Simulates actual user workflows and validates complete system integration
"""
import os
import sys
import django
from datetime import datetime
import json

# Setup Django environment
sys.path.append('/Users/ian/Desktop/VIBECODE/PrimePath/primepath_project')
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'primepath_project.settings_sqlite')
django.setup()

from django.contrib.auth.models import User
from django.test import RequestFactory, Client
from django.template.loader import render_to_string
from primepath_routinetest.models import Exam, TeacherClassAssignment, ExamScheduleMatrix
from primepath_routinetest.views.classes_exams_unified import classes_exams_unified_view
from core.models import Teacher
import uuid

def comprehensive_qa_validation():
    """Comprehensive QA validation from user perspective"""
    print("\n" + "="*80)
    print("ğŸ” COMPREHENSIVE QA VALIDATION - MATRIX RESTORATION")
    print("   End-to-end validation of restored matrix functionality")
    print("="*80)
    
    validation_results = {
        'total_validations': 0,
        'passed_validations': 0,
        'failed_validations': 0,
        'warnings': [],
        'critical_issues': [],
        'user_experience_score': 0
    }
    
    # Setup test data
    admin_user, created = User.objects.get_or_create(
        username='admin',
        defaults={
            'is_superuser': True,
            'is_staff': True,
            'email': 'admin@example.com'
        }
    )
    
    if created:
        admin_user.set_password('admin')
        admin_user.save()
    
    # Create test client
    client = Client()
    client.force_login(admin_user)
    
    # QA Validation 1: Admin User Experience
    print("\nğŸ‘‘ 1. ADMIN USER EXPERIENCE VALIDATION...")
    validation_results['total_validations'] += 1
    
    try:
        # Simulate admin accessing Classes & Exams
        response = client.get('/RoutineTest/classes-exams/')
        
        if response.status_code == 200:
            print("   âœ… Admin can access Classes & Exams page")
            
            # Check response content for expected elements
            content = response.content.decode()
            
            # Validate matrix presence
            expected_elements = [
                'matrix-table',
                'matrix-cell',
                'ADMIN - Full Access to All Classes',
                'Schedule Matrix Preview',
                'Classes & Exams Management'
            ]
            
            element_score = 0
            for element in expected_elements:
                if element in content:
                    element_score += 1
                    print(f"   âœ… Found: {element}")
                else:
                    print(f"   âš ï¸ Missing: {element}")
                    validation_results['warnings'].append(f"Missing UI element: {element}")
            
            # Score calculation
            ui_score = (element_score / len(expected_elements)) * 100
            print(f"   ğŸ“Š UI Completeness: {ui_score:.1f}% ({element_score}/{len(expected_elements)})")
            
            if ui_score >= 80:
                validation_results['passed_validations'] += 1
                validation_results['user_experience_score'] += 20
            else:
                validation_results['failed_validations'] += 1
                validation_results['critical_issues'].append("Admin UI incomplete")
        else:
            print(f"   âŒ Admin cannot access page: {response.status_code}")
            validation_results['failed_validations'] += 1
            validation_results['critical_issues'].append("Admin access denied")
            
    except Exception as e:
        print(f"   âŒ Admin validation error: {str(e)}")
        validation_results['failed_validations'] += 1
        validation_results['critical_issues'].append(f"Admin validation exception: {str(e)}")
    
    # QA Validation 2: Matrix Data Integrity
    print("\nğŸ—„ï¸ 2. MATRIX DATA INTEGRITY VALIDATION...")
    validation_results['total_validations'] += 1
    
    try:
        # Test matrix data structure integrity
        factory = RequestFactory()
        request = factory.get('/RoutineTest/classes-exams/')
        request.user = admin_user
        
        # Call the view directly to get context data
        response = classes_exams_unified_view(request)
        
        if response.status_code == 200:
            print("   âœ… Matrix view processing successful")
            
            # Check if context contains expected matrix data
            # Since we can't directly access context, we validate data through models
            
            # Validate ExamScheduleMatrix model
            current_year = str(datetime.now().year)
            test_matrix_cells = ExamScheduleMatrix.objects.filter(
                academic_year=current_year
            )
            
            print(f"   ğŸ“Š Matrix cells in database: {test_matrix_cells.count()}")
            
            # Test matrix cell methods
            if test_matrix_cells.exists():
                test_cell = test_matrix_cells.first()
                
                # Test key matrix cell methods
                method_tests = [
                    ('get_exam_count', test_cell.get_exam_count),
                    ('get_status_color', test_cell.get_status_color),
                    ('get_status_icon', test_cell.get_status_icon),
                    ('get_time_period_display', test_cell.get_time_period_display),
                    ('get_class_display', test_cell.get_class_display)
                ]
                
                method_success = 0
                for method_name, method in method_tests:
                    try:
                        result = method()
                        print(f"   âœ… {method_name}(): {result}")
                        method_success += 1
                    except Exception as method_error:
                        print(f"   âŒ {method_name}() failed: {method_error}")
                        validation_results['warnings'].append(f"Matrix method {method_name} failed")
                
                method_score = (method_success / len(method_tests)) * 100
                print(f"   ğŸ“Š Matrix Methods: {method_score:.1f}% working")
                
                if method_score >= 90:
                    validation_results['passed_validations'] += 1
                    validation_results['user_experience_score'] += 15
                else:
                    validation_results['failed_validations'] += 1
                    validation_results['critical_issues'].append("Matrix method failures")
            else:
                print("   âš ï¸ No matrix cells found - creating test data...")
                # Create test matrix cell
                test_cell, created = ExamScheduleMatrix.get_or_create_cell(
                    class_code='CLASS_7A',
                    academic_year=current_year,
                    time_period_type='MONTHLY',
                    time_period_value='JAN',
                    user=admin_user
                )
                
                if created:
                    print("   âœ… Test matrix cell created successfully")
                    validation_results['passed_validations'] += 1
                    validation_results['user_experience_score'] += 10
                else:
                    print("   âœ… Test matrix cell already exists")
                    validation_results['passed_validations'] += 1
                    validation_results['user_experience_score'] += 10
        else:
            print(f"   âŒ Matrix view failed: {response.status_code}")
            validation_results['failed_validations'] += 1
            validation_results['critical_issues'].append("Matrix view processing failed")
            
    except Exception as e:
        print(f"   âŒ Matrix data validation error: {str(e)}")
        validation_results['failed_validations'] += 1
        validation_results['critical_issues'].append(f"Matrix data exception: {str(e)}")
    
    # QA Validation 3: Template Rendering Validation
    print("\nğŸ¨ 3. TEMPLATE RENDERING VALIDATION...")
    validation_results['total_validations'] += 1
    
    try:
        # Test template filters
        from primepath_routinetest.templatetags.matrix_filters import dict_get, get_item, matrix_cell
        
        # Test filter functionality
        test_matrix_data = {
            'CLASS_7A': {
                'JAN': {'has_exam': True, 'exam_count': 2},
                'FEB': {'has_exam': False, 'exam_count': 0}
            }
        }
        
        filter_tests = [
            ('dict_get', lambda: dict_get(test_matrix_data['CLASS_7A'], 'JAN')),
            ('get_item', lambda: get_item(test_matrix_data, 'CLASS_7A')),
        ]
        
        filter_success = 0
        for filter_name, filter_func in filter_tests:
            try:
                result = filter_func()
                if result is not None:
                    print(f"   âœ… {filter_name} filter working: {result}")
                    filter_success += 1
                else:
                    print(f"   âš ï¸ {filter_name} filter returned None")
                    validation_results['warnings'].append(f"Filter {filter_name} returned None")
            except Exception as filter_error:
                print(f"   âŒ {filter_name} filter failed: {filter_error}")
                validation_results['warnings'].append(f"Filter {filter_name} failed")
        
        # Test template loading
        try:
            from django.template.loader import get_template
            template = get_template('primepath_routinetest/classes_exams_unified.html')
            print("   âœ… Main template loads successfully")
            filter_success += 1
        except Exception as template_error:
            print(f"   âŒ Template loading failed: {template_error}")
            validation_results['warnings'].append("Template loading failed")
        
        filter_score = (filter_success / 3) * 100
        print(f"   ğŸ“Š Template System: {filter_score:.1f}% working")
        
        if filter_score >= 80:
            validation_results['passed_validations'] += 1
            validation_results['user_experience_score'] += 15
        else:
            validation_results['failed_validations'] += 1
            validation_results['critical_issues'].append("Template system issues")
            
    except Exception as e:
        print(f"   âŒ Template validation error: {str(e)}")
        validation_results['failed_validations'] += 1
        validation_results['critical_issues'].append(f"Template validation exception: {str(e)}")
    
    # QA Validation 4: Performance and Scalability
    print("\nâš¡ 4. PERFORMANCE AND SCALABILITY VALIDATION...")
    validation_results['total_validations'] += 1
    
    try:
        # Test performance with multiple requests
        start_time = datetime.now()
        
        performance_tests = []
        for i in range(5):  # Test 5 requests
            request_start = datetime.now()
            response = client.get('/RoutineTest/classes-exams/')
            request_end = datetime.now()
            
            duration = (request_end - request_start).total_seconds()
            performance_tests.append({
                'request': i + 1,
                'duration': duration,
                'status': response.status_code
            })
        
        total_time = (datetime.now() - start_time).total_seconds()
        avg_response_time = sum(test['duration'] for test in performance_tests) / len(performance_tests)
        
        print(f"   ğŸ“Š Total time for 5 requests: {total_time:.2f}s")
        print(f"   ğŸ“Š Average response time: {avg_response_time:.2f}s")
        
        # Performance criteria
        performance_score = 0
        if avg_response_time < 1.0:  # Under 1 second average
            print("   âœ… Excellent performance (< 1s avg)")
            performance_score = 100
        elif avg_response_time < 2.0:  # Under 2 seconds average
            print("   âœ… Good performance (< 2s avg)")
            performance_score = 80
        elif avg_response_time < 5.0:  # Under 5 seconds average
            print("   âš ï¸ Acceptable performance (< 5s avg)")
            performance_score = 60
        else:
            print("   âŒ Poor performance (> 5s avg)")
            performance_score = 30
            validation_results['critical_issues'].append("Performance issues detected")
        
        print(f"   ğŸ“Š Performance Score: {performance_score}%")
        
        if performance_score >= 70:
            validation_results['passed_validations'] += 1
            validation_results['user_experience_score'] += performance_score * 0.2  # Max 20 points
        else:
            validation_results['failed_validations'] += 1
            
    except Exception as e:
        print(f"   âŒ Performance validation error: {str(e)}")
        validation_results['failed_validations'] += 1
        validation_results['critical_issues'].append(f"Performance validation exception: {str(e)}")
    
    # QA Validation 5: Error Handling and Robustness
    print("\nğŸ›¡ï¸ 5. ERROR HANDLING AND ROBUSTNESS VALIDATION...")
    validation_results['total_validations'] += 1
    
    try:
        # Test error scenarios
        error_scenarios = [
            {
                'name': 'Invalid year parameter',
                'url': '/RoutineTest/classes-exams/?year=invalid',
                'expected_status': [200, 400]  # Should handle gracefully
            },
            {
                'name': 'Empty matrix data',
                'test': 'matrix_with_no_data',
                'expected_status': [200]  # Should handle empty state
            }
        ]
        
        error_handling_score = 0
        total_error_tests = len(error_scenarios)
        
        for scenario in error_scenarios:
            try:
                if 'url' in scenario:
                    response = client.get(scenario['url'])
                    if response.status_code in scenario['expected_status']:
                        print(f"   âœ… {scenario['name']}: Handled gracefully")
                        error_handling_score += 1
                    else:
                        print(f"   âŒ {scenario['name']}: Status {response.status_code}")
                        validation_results['warnings'].append(f"Error handling issue: {scenario['name']}")
                elif scenario['test'] == 'matrix_with_no_data':
                    # Test with user that has no class assignments
                    test_user = User.objects.create_user(
                        username=f'test_user_{uuid.uuid4().hex[:8]}',
                        password='testpass'
                    )
                    client.force_login(test_user)
                    response = client.get('/RoutineTest/classes-exams/')
                    
                    if response.status_code in scenario['expected_status']:
                        print(f"   âœ… No data scenario: Handled gracefully")
                        error_handling_score += 1
                    else:
                        print(f"   âŒ No data scenario: Status {response.status_code}")
                        validation_results['warnings'].append("Empty data not handled")
                    
                    # Switch back to admin
                    client.force_login(admin_user)
                    
            except Exception as scenario_error:
                print(f"   âš ï¸ {scenario['name']}: Exception handled - {scenario_error}")
                # Exceptions are sometimes expected, so this might be OK
                error_handling_score += 0.5
        
        error_score = (error_handling_score / total_error_tests) * 100
        print(f"   ğŸ“Š Error Handling: {error_score:.1f}% robust")
        
        if error_score >= 70:
            validation_results['passed_validations'] += 1
            validation_results['user_experience_score'] += 15
        else:
            validation_results['failed_validations'] += 1
            validation_results['critical_issues'].append("Error handling insufficient")
            
    except Exception as e:
        print(f"   âŒ Error handling validation error: {str(e)}")
        validation_results['failed_validations'] += 1
        validation_results['critical_issues'].append(f"Error handling validation exception: {str(e)}")
    
    # Final QA Summary
    print(f"\nğŸ“Š COMPREHENSIVE QA VALIDATION SUMMARY")
    print(f"="*60)
    print(f"Total Validations:     {validation_results['total_validations']}")
    print(f"Passed Validations:    {validation_results['passed_validations']}")
    print(f"Failed Validations:    {validation_results['failed_validations']}")
    
    success_rate = (validation_results['passed_validations'] / validation_results['total_validations']) * 100
    print(f"Success Rate:          {success_rate:.1f}%")
    print(f"User Experience Score: {validation_results['user_experience_score']:.1f}/100")
    
    # Quality Assessment
    if success_rate >= 90 and validation_results['user_experience_score'] >= 80:
        quality_rating = "EXCELLENT"
        overall_pass = True
    elif success_rate >= 80 and validation_results['user_experience_score'] >= 70:
        quality_rating = "GOOD"
        overall_pass = True
    elif success_rate >= 70 and validation_results['user_experience_score'] >= 60:
        quality_rating = "ACCEPTABLE"
        overall_pass = True
    else:
        quality_rating = "NEEDS IMPROVEMENT"
        overall_pass = False
    
    print(f"\nğŸ† OVERALL QUALITY RATING: {quality_rating}")
    
    # Issues Summary
    if validation_results['critical_issues']:
        print(f"\nğŸš¨ CRITICAL ISSUES:")
        for issue in validation_results['critical_issues']:
            print(f"   âŒ {issue}")
    
    if validation_results['warnings']:
        print(f"\nâš ï¸ WARNINGS ({len(validation_results['warnings'])}):")
        for warning in validation_results['warnings'][:5]:  # Show first 5
            print(f"   âš ï¸ {warning}")
        if len(validation_results['warnings']) > 5:
            print(f"   ... and {len(validation_results['warnings']) - 5} more warnings")
    
    # Final Verdict
    if overall_pass:
        print(f"\nğŸ‰ QA VALIDATION PASSED!")
        print(f"âœ… Matrix functionality restoration is complete and ready for production")
        print(f"âœ… All critical features working correctly")
        print(f"âœ… User experience meets quality standards")
    else:
        print(f"\nâš ï¸ QA VALIDATION NEEDS ATTENTION")
        print(f"âŒ Some issues detected that should be addressed")
        print(f"âŒ Review critical issues before deployment")
    
    print("="*60)
    
    return overall_pass, validation_results

if __name__ == "__main__":
    success, results = comprehensive_qa_validation()
    if success:
        print("\nğŸš€ RESULT: Comprehensive QA validation PASSED!")
        sys.exit(0)
    else:
        print("\nğŸ’¥ RESULT: Comprehensive QA validation needs attention!")
        sys.exit(1)